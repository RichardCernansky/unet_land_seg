{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsEqwYA1LTfT"
   },
   "source": [
    "# **U-NET Data modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rz7aoU2X5tGV"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDP0FbvP_BAz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "os.makedirs(\"files/non_aug\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRq4quABK8Vd"
   },
   "outputs": [],
   "source": [
    "# Set the seed values\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(42)  # Ensures hash-based randomness is fixed\n",
    "np.random.seed(42)  # NumPy random seed\n",
    "tf.random.set_seed(42)  # TensorFlow random seed\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 8       # Number of images per batch\n",
    "lr = 1e-4            # Learning rate (0.0001)\n",
    "epochs = 100         # Total number of training epochs\n",
    "height = 256         # Input image height\n",
    "width = 256          # Input image width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTn9x6loNvTu"
   },
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\"/content/dataset\", \"aug\")\n",
    "files_dir = os.path.join(\"files\", \"non_aug\")\n",
    "model_file = os.path.join(files_dir, \"unet-non-aug.keras\")\n",
    "log_file = os.path.join(files_dir, \"log-non-aug.csv\")\n",
    "\n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "valid_path = os.path.join(dataset_path, \"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNuZgbRhN6oZ"
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUIUrjzW5xSL"
   },
   "source": [
    "# U-NET definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sw-jneVrPgIa"
   },
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    \"\"\" Convolutional block: Two Conv2D layers with Batch Normalization & ReLU activation. \"\"\"\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    \"\"\" Encoder Block: Convolutional block + MaxPooling \"\"\"\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    \"\"\" Decoder Block: Upsampling + Skip Connection + Convolutional Block \"\"\"\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)  # Upsample\n",
    "    x = Concatenate()([x, skip])  # Skip connection\n",
    "    x = conv_block(x, num_filters)  # Apply conv block\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04yv-sM4TJRi"
   },
   "outputs": [],
   "source": [
    "def build_unet(input_shape=(256, 256, 3), num_classes=3):\n",
    "    \"\"\" U-Net Model for Multi-Class Segmentation \"\"\"\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    \"\"\" Output Layer for Multi-Class Segmentation \"\"\"\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\")(d4)  # ❌ No activation\n",
    "\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"UNET_MultiClass\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRhwVzvBTgHh"
   },
   "source": [
    "# **Dataset pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oc66NNnn2LnJ"
   },
   "outputs": [],
   "source": [
    "# Define RGB values for each class\n",
    "BACKGROUND_COLOR = [0, 0, 0]  # Black (Background)\n",
    "ROAD_COLOR = [128, 128, 128]  # Gray (Roads)\n",
    "RODENT_COLOR = [255, 0, 0]  # Red (Rodents)\n",
    "\n",
    "# Dictionary for easy access\n",
    "CLASS_COLORS = {\n",
    "    0: BACKGROUND_COLOR,  # Background\n",
    "    1: ROAD_COLOR,  # Roads\n",
    "    2: RODENT_COLOR  # Rodents\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfkOGcdt2MZf"
   },
   "outputs": [],
   "source": [
    "def encode_mask(mask):\n",
    "    # Create an empty mask with class labels\n",
    "    new_mask = np.zeros(mask.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Assign class labels based on color\n",
    "    new_mask[np.all(mask == ROAD_COLOR, axis=-1)] = 1  # Roads -> Class 1\n",
    "    new_mask[np.all(mask == RODENT_COLOR, axis=-1)] = 2  # Rodents -> Class 2\n",
    "    # Background remains 0\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "def decode_mask(mask):\n",
    "    # Create an empty RGB mask\n",
    "    rgb_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Assign RGB colors based on class labels\n",
    "    for class_id, color in CLASS_COLORS.items():\n",
    "        rgb_mask[mask == class_id] = color\n",
    "\n",
    "    return rgb_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMpMLrp-Tlml"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # Load training images and masks\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\")))\n",
    "\n",
    "    # Load validation images and masks\n",
    "    valid_x = sorted(glob(os.path.join(path, \"val\", \"images\", \"*\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"val\", \"masks\", \"*\")))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4iAv2yb7yQbt"
   },
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()  # Decode bytes to string (for TensorFlow datasets)\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)  # Read image in color mode\n",
    "    x = x / 255.0  # Normalize pixel values to range [0,1]\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()  # Decode bytes to string (for TensorFlow dataset pipelines)\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)  # Read mask as a color image\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB) #invert because of open cv\n",
    "    x = encode_mask(x)  # Convert to class labels {0,1,2}\n",
    "    x  = np.expand_dims(x, axis=-1)\n",
    "    x= x.astype(np.double)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBkIJRDfzcbA"
   },
   "source": [
    "**tf.dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WstNGQ8KzGsX"
   },
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)  # Read and preprocess the image\n",
    "        y = read_mask(y)   # Read and preprocess the mask\n",
    "        return x, y\n",
    "\n",
    "    # Convert Python function into a TensorFlow operation\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "\n",
    "    # Set explicit shapes for TensorFlow tensors\n",
    "    x.set_shape([height, width, 3])  # Image shape (H, W, 3 channels)\n",
    "    y.set_shape([height, width, 1])  # Mask shape (H, W, 1 channel)\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=8):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((x, y))  # Create dataset from file paths\n",
    "  dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)  # Preprocess images/masks\n",
    "  dataset = dataset.batch(batch)  # Group data into batches\n",
    "  dataset = dataset.prefetch(tf.data.AUTOTUNE)  # Optimize data loading\n",
    "  return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n62ShD21uOX_"
   },
   "source": [
    "## **Loss definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnZ0TfyvuNUm"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice coefficient loss function.\n",
    "    \"\"\"\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])  # Adjust axis for your data format\n",
    "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
    "    dice = K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Dice loss (1 - dice_coef).  Minimizing this is equivalent to maximizing Dice.\n",
    "    \"\"\"\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Combines Binary Cross-Entropy (BCE) loss and Dice loss.\n",
    "    \"\"\"\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)  # Use TensorFlow's BCE\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return 0.5 * bce + 0.5 * dice  # Adjust weights as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8Em5HnQzhW-"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQYNhFsEzhzj"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
    "\n",
    "# Print dataset size\n",
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTEKjavrXhpp"
   },
   "source": [
    "**Check shape of train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "zYeOJklZ4f3z"
   },
   "outputs": [],
   "source": [
    "for x,y in train_dataset:\n",
    "  print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWDRg5Ez5lKT"
   },
   "source": [
    "**Model summary and callback definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "rmwcDMR45iAm"
   },
   "outputs": [],
   "source": [
    "input_shape = (height, width, 3)\n",
    "model = build_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzdoxGyZW-Cg"
   },
   "source": [
    "**Model compile and fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mLIm4cp1MF-"
   },
   "outputs": [],
   "source": [
    "# Create U-Net model for 3-class segmentation\n",
    "num_classes = 3  # Background, Roads, Rodents\n",
    "model = build_unet(num_classes=num_classes)\n",
    "\n",
    "# Compile model with Sparse Categorical Crossentropy loss\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # ✅ Handles logits correctly\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "3du3PLFoVkaO"
   },
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, mode='max', verbose=1),\n",
    "    CSVLogger(log_file),\n",
    "    EarlyStopping(monitor='val_loss', patience=15, mode='max', restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model with increased epochs\n",
    "history = model.fit(\n",
    "    train_dataset,                  # Replace with your training dataset\n",
    "    validation_data=valid_dataset,  # Replace with your validation dataset\n",
    "    epochs=13,                     # Increased number of epochs\n",
    "    callbacks=callbacks,\n",
    "    verbose=1                       # Display detailed training logs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkTIBuXyp5rg"
   },
   "source": [
    "**Save model and hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_odQjAPNp4zA"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/unet_land_seg/unet_model_multiclass.keras')  # Saves in Google Drive\n",
    "# tuner_path = \"/content/hyperband_tuning\"\n",
    "# drive_path = \"/content/drive/MyDrive/unet_land_seg/hyperband_tuning\"\n",
    "\n",
    "# # Copy the tuner directory to Google Drive\n",
    "# shutil.copytree(tuner_path, drive_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqrc5lIn3Q29"
   },
   "source": [
    "**Model fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iFL4eVd7D_v"
   },
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=valid_dataset,\n",
    "#     epochs=epochs,\n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBLbnlb_3GkS"
   },
   "source": [
    "**Load model from file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5wwT7n-vzd81"
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.get_custom_objects()[\"bce_dice_loss\"] = bce_dice_loss\n",
    "# model_path = \"files/non_aug/unet-non-aug.keras\"\n",
    "# model = tf.keras.models.load_model(model_path, custom_objects={\"bce_dice_loss\": bce_dice_loss})\n",
    "\n",
    "# # Print model summary to verify\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAezLWBt5d3D"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlR93Xgu3MGv"
   },
   "source": [
    "**Plot metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Nr2NP254O5Ch"
   },
   "outputs": [],
   "source": [
    "# Load training log\n",
    "log_file = \"files/non_aug/log-non-aug.csv\"\n",
    "history_df = pd.read_csv(log_file)\n",
    "\n",
    "# Check available columns\n",
    "print(\"Available columns:\", history_df.columns)\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_df[\"loss\"], label=\"Training Loss\", color=\"blue\", linestyle=\"dashed\")\n",
    "plt.plot(history_df[\"val_loss\"], label=\"Validation Loss\", color=\"red\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot Training and Validation Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_df[\"accuracy\"], label=\"Training Accuracy\", color=\"green\", linestyle=\"dashed\")\n",
    "plt.plot(history_df[\"val_accuracy\"], label=\"Validation Accuracy\", color=\"purple\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbqnxL2yxEzr"
   },
   "source": [
    "**Plot prediciton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uekytXaWxHZS"
   },
   "outputs": [],
   "source": [
    "# Function to read and normalize an image for visualization\n",
    "def read_image_for_plot(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)  # Read image in color mode (H, W, 3)\n",
    "    x = x / 255.0  # Normalize pixel values to range [0,1]\n",
    "    return x\n",
    "\n",
    "# Function to read and preprocess a multi-class mask for visualization\n",
    "def read_mask_for_plot(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)  # Read mask in color mode\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    return x.astype(np.uint8)  # Ensure integer labels\n",
    "\n",
    "# Select a sample validation image and mask\n",
    "sample_image_path = valid_x[5]  # Select an image path\n",
    "sample_mask_path = valid_y[5]  # Select corresponding mask path\n",
    "sample_image_path = \"/content/dataset/aug/val/images/HL1.tif_patch_25_69.tif\"\n",
    "sample_mask_path = \"/content/dataset/aug/val/masks/HL1.png_patch_25_69.png\"\n",
    "\n",
    "\n",
    "sample_image = read_image_for_plot(sample_image_path)  # Load image\n",
    "\n",
    "sample_mask = read_mask_for_plot(sample_mask_path)\n",
    "\n",
    "\n",
    "# Ensure correct shape for model input\n",
    "input_image = np.expand_dims(sample_image, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict the mask\n",
    "pred_mask = model.predict(input_image)  # Model outputs (H, W, num_classes)\n",
    "\n",
    "\n",
    "# Apply softmax if model outputs logits\n",
    "pred_mask = tf.nn.softmax(pred_mask[0], axis=-1)  # Convert logits to probabilities\n",
    "pred_mask = np.argmax(pred_mask, axis=-1)  # Convert probabilities to class indices\n",
    "decoded_mask = decode_mask(pred_mask)  # Convert to RGB mask for visualization\n",
    "\n",
    "# Plot the original image, ground truth, and predicted mask\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(sample_image)  # Original image\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(sample_mask)  # Ground truth mask (converted to RGB)\n",
    "axes[1].set_title(\"Ground Truth Mask\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(decoded_mask)  # Predicted mask\n",
    "axes[2].set_title(\"Predicted Mask\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
